{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f53bea-fefb-478f-9ba0-640fe7437e3e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a70a4a-16f5-4b0c-b81d-8959032ae55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "# import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from near_regex import NEAR_regex  # copy this file into the asgn folder\n",
    "from tqdm import tqdm  # progress bar on loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfadaba-7f99-4f53-8278-18682dc448ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File handling\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d419bcd-216c-4760-a4fe-180b89c7c21f",
   "metadata": {},
   "source": [
    "## Load sentiment dictionaries\n",
    "\n",
    "TODO: justify that positive values as of 2021 are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8025a5e8-5384-4cc7-87ac-0ebdad9212af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Dictionaries\n",
    "with open('inputs/ML_negative_unigram.txt', 'r') as file:\n",
    "    BHR_negative = [line.strip() for line in file]\n",
    "with open('inputs/ML_positive_unigram.txt', 'r') as file:\n",
    "    BHR_positive = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8936ac5-2136-4730-8a72-c582d7d5c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM Dictionaries\n",
    "LM = pd.read_csv('inputs/LM_MasterDictionary_1993-2021.csv')\n",
    "LM_negative = LM.query('Negative > 0')['Word'].to_list()\n",
    "LM_positive = LM.query('Positive > 0')['Word'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b45f5f-e4de-4d83-8ae1-014115d1b1b5",
   "metadata": {},
   "source": [
    "## Load 2022 returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db8388d-726a-4d46-aeb5-01c7e2700566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>-0.011276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>0.030954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>0.014362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>0.012459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594044</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>-0.017551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594045</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>-0.114089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594046</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>0.033089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594047</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>0.080827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594048</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.011164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2594049 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker       date       ret\n",
       "0         JJSF 2021-12-01 -0.011276\n",
       "1         JJSF 2021-12-02  0.030954\n",
       "2         JJSF 2021-12-03  0.000287\n",
       "3         JJSF 2021-12-06  0.014362\n",
       "4         JJSF 2021-12-07  0.012459\n",
       "...        ...        ...       ...\n",
       "2594044   TSLA 2022-12-23 -0.017551\n",
       "2594045   TSLA 2022-12-27 -0.114089\n",
       "2594046   TSLA 2022-12-28  0.033089\n",
       "2594047   TSLA 2022-12-29  0.080827\n",
       "2594048   TSLA 2022-12-30  0.011164\n",
       "\n",
       "[2594049 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_path = \"inputs/crsp_2022.zip\"\n",
    "\n",
    "# if not os.path.exists(stock_path):\n",
    "url = \"https://github.com/LeDataSciFi/data/raw/main/Stock%20Returns%20(CRSP)/crsp_2022_only.zip\"\n",
    "with urlopen(url) as request:\n",
    "    data = BytesIO(request.read())\n",
    "\n",
    "with ZipFile(data) as archive:\n",
    "    with archive.open(archive.namelist()[0]) as stata:\n",
    "        stock_rets = pd.read_stata(stata)\n",
    "\n",
    "stock_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc85e2a-0ec6-4231-bafd-a00dc9c71ec1",
   "metadata": {},
   "source": [
    "## Load each firm and add sentiment variables\n",
    "\n",
    "TODO: load and clean\n",
    "\n",
    "For each firm, \n",
    "\n",
    "- [ ] load the corresponding 10-K. Clean the text.\n",
    "\n",
    "- [ ] Create the sentiment measurements, and save those new measurements to the correct row and column in the dataframe.\n",
    "\n",
    "- [ ] Bonus: Save the total length of the document (# of words)\n",
    "\n",
    "- [ ] Bonus: Save the # of unique words (similar to total length)\n",
    "\n",
    "- [ ] Calculate returns from t to t+2 inclusive\n",
    "\n",
    "- [ ] Calculate returns from t+3 to t+10 inclusive\n",
    "\n",
    "- [ ] Download 2021 accounting data (2021 ccm_cleaned.dta) from the data repo (possibly useful in analysis) and add to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab6e2a7-47f6-446d-8dbf-558eeb76bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather sentiments into regex\n",
    "BHR_negative_regex = '(' + '|'.join(BHR_negative).lower() + ')'\n",
    "BHR_positive_regex = '(' + '|'.join(BHR_positive).lower() + ')'\n",
    "LM_negative_regex = '(' + '|'.join(LM_negative).lower() + ')'\n",
    "LM_positive_regex = '(' + '|'.join(LM_positive).lower() + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69ecbb34-6075-4967-9f6a-45afece8fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic regex\n",
    "\n",
    "# Socially responsible investing\n",
    "esg_topics = ['esg', 'sustainability', 'impact invest', 'ethical', \n",
    "              'clean energy', 'gender', 'diversity', 'inclusion',\n",
    "              'microfinance', 'cdfi']\n",
    "esg_negative = ['limited', 'limit', 'underdeveloped', 'underdevelop',\n",
    "                'bureaucratic', 'slow', 'insufficient']\n",
    "esg_positive = ['ethical', 'sustainable', 'profitable', 'profit',\n",
    "                'innovative', 'innovation', 'transformative', 'transform']\n",
    "\n",
    "# Ecommerce\n",
    "ecom_topics = ['online', 'digital payment', 'logistics', 'delivery', \n",
    "               'mobile commerce', 'social commerce', 'dropship',\n",
    "               'drop ship', 'social media']\n",
    "ecom_negative = ['risky', 'unsustainable',  'unsustained', 'monopoly',\n",
    "                 'monopolistic', 'unethical']\n",
    "ecom_positive = ['convenienent', 'convenienence', 'accessible', 'access',\n",
    "                 'innovative', 'innovation', 'profitable', 'profit',\n",
    "                 'efficient']\n",
    "\n",
    "# Biotech and healthcare\n",
    "bio_topics = ['gene', 'biopharm', 'telemedic', 'personalized medic',\n",
    "              'medical device', 'vaccine', 'precision medic', 'organ',\n",
    "              'regenerative medic', 'prosthetic', 'clinic', 'fda',\n",
    "              'health']\n",
    "bio_negative = ['risky', 'expensive', 'slow', 'controversial', 'unethical']\n",
    "bio_positive = ['new', 'safe', 'innovative', 'innovation',\n",
    "                'transformative', 'transform', 'life', 'lives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be15445f-5c9e-40a6-be0a-16015841d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_path = \"inputs/s&p500_2022.csv\"\n",
    "\n",
    "if not os.path.exists(sp500_path):\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    pd.read_html(url)[0].to_csv(sp500_path, index=False)  # [1] shows updates\n",
    "\n",
    "sp500 = pd.read_csv(sp500_path)[['Symbol', 'Security', 'CIK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81201d43-c23b-4601-bade-b3eadad933cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>CIK</th>\n",
       "      <th>word_count</th>\n",
       "      <th>bhr_negative</th>\n",
       "      <th>bhr_positive</th>\n",
       "      <th>lm_negative</th>\n",
       "      <th>lm_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>66740</td>\n",
       "      <td>76432.0</td>\n",
       "      <td>0.044314</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.043097</td>\n",
       "      <td>0.015125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>91142</td>\n",
       "      <td>33810.0</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.038391</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.013162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>1800</td>\n",
       "      <td>52061.0</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.039761</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.010584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>1551152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>1467373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>1041061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>877212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>1136869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorporation</td>\n",
       "      <td>109380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>1555280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol              Security      CIK  word_count  bhr_negative  \\\n",
       "0      MMM                    3M    66740     76432.0      0.044314   \n",
       "1      AOS           A. O. Smith    91142     33810.0      0.032919   \n",
       "2      ABT                Abbott     1800     52061.0      0.039492   \n",
       "3     ABBV                AbbVie  1551152         NaN           NaN   \n",
       "4      ACN             Accenture  1467373         NaN           NaN   \n",
       "..     ...                   ...      ...         ...           ...   \n",
       "498    YUM           Yum! Brands  1041061         NaN           NaN   \n",
       "499   ZBRA    Zebra Technologies   877212         NaN           NaN   \n",
       "500    ZBH         Zimmer Biomet  1136869         NaN           NaN   \n",
       "501   ZION  Zions Bancorporation   109380         NaN           NaN   \n",
       "502    ZTS                Zoetis  1555280         NaN           NaN   \n",
       "\n",
       "     bhr_positive  lm_negative  lm_positive  \n",
       "0        0.041750     0.043097     0.015125  \n",
       "1        0.038391     0.034102     0.013162  \n",
       "2        0.039761     0.036246     0.010584  \n",
       "3             NaN          NaN          NaN  \n",
       "4             NaN          NaN          NaN  \n",
       "..            ...          ...          ...  \n",
       "498           NaN          NaN          NaN  \n",
       "499           NaN          NaN          NaN  \n",
       "500           NaN          NaN          NaN  \n",
       "501           NaN          NaN          NaN  \n",
       "502           NaN          NaN          NaN  \n",
       "\n",
       "[503 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firm_10k_path = \"10k_files/sec-edgar-filings\"\n",
    "\n",
    "for i in tqdm(range(len(sp500[:3]))):    # TODO\n",
    "    tic = sp500['Symbol'].iloc[i]\n",
    "    \n",
    "    # Check existence of path\n",
    "    if not os.path.exists(fr'{firm_10k_path}/{tic}'):\n",
    "        print(f'Cannot find 10-K for ticker {tic}')\n",
    "        continue\n",
    "    \n",
    "    # Open 10-K\n",
    "    for path in glob.glob(fr'{firm_10k_path}/{tic}/*/*/*.html'): #'/*/*.xml'):\n",
    "        with open(path, 'rb') as report_file:\n",
    "            html = report_file.read()\n",
    "        soup = BeautifulSoup(html, 'lxml-xml')\n",
    "        for div in soup.find_all(\"div\", {'style': 'display:none'}):\n",
    "            div.decompose()\n",
    "        lower = soup.get_text().lower()\n",
    "        no_punc = re.sub(r'\\W', ' ', lower)\n",
    "        cleaned = re.sub(r'\\s+', ' ', no_punc)\n",
    "    \n",
    "        # Gather sentiment variables\n",
    "        sp500.loc[i, 'word_count'] = len(re.findall(r'\\w+', cleaned))\n",
    "        sp500.loc[i, 'bhr_negative'] = \\\n",
    "                len(re.findall(BHR_negative_regex, cleaned)) / \\\n",
    "                sp500.loc[i, 'word_count']\n",
    "        sp500.loc[i, 'bhr_positive'] = \\\n",
    "                len(re.findall(BHR_positive_regex, cleaned)) / \\\n",
    "                sp500.loc[i, 'word_count']\n",
    "        sp500.loc[i, 'lm_negative'] = \\\n",
    "                len(re.findall(LM_negative_regex, cleaned)) / \\\n",
    "                sp500.loc[i, 'word_count']\n",
    "        sp500.loc[i, 'lm_positive'] = \\\n",
    "                len(re.findall(LM_positive_regex, cleaned)) / \\\n",
    "                sp500.loc[i, 'word_count']\n",
    "        \n",
    "    # if os.path.exists()\n",
    "    # print(i, sp500['Symbol'].iloc[i])\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587262d6-62f7-4921-bb11-ae22bc157dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get list of firms this way or just with os.list dir\n",
    "# firm_10k_path = \"10k_files/sec-edgar-filings\"\n",
    "\n",
    "# if not os.path.exists(firm_10k_path):\n",
    "#     print(\"Cannot find 10-K files.\")\n",
    "# else:\n",
    "#     firms = os.listdir(firm_10k_path)\n",
    "    \n",
    "#     for firm in firms[:3]: # TODO\n",
    "#         for path in glob.glob(fr'{firm_10k_path}/{firm}/*/*/*.html'): #'/*/*.xml'):\n",
    "#             with open(path, 'rb') as report_file:\n",
    "#                 html = report_file.read()\n",
    "#             soup = BeautifulSoup(html, 'lxml-xml')\n",
    "#             for div in soup.find_all(\"div\", {'style': 'display:none'}):\n",
    "#                 div.decompose()\n",
    "#             lower = soup.get_text().lower()\n",
    "#             no_punc = re.sub(r'\\W', ' ', lower)\n",
    "#             cleaned = re.sub(r'\\s+', ' ', no_punc)\n",
    "            \n",
    "#             print(path)\n",
    "            \n",
    "\n",
    "# # Create the pandas set\n",
    "# for firm in firms:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89391a-1bf8-40a1-88b7-6b2efe8e9cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4685d86b-4e36-4871-aa3a-0f0a11942775",
   "metadata": {},
   "source": [
    "## Add 10-K sentiment data\n",
    "\n",
    "TODO: load and clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29691e2-acc7-4588-bb85-0bd161b71d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36f481ec-45af-40e1-a139-e4b4800607ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100815c-41e1-405a-8a0f-e4d2964233f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
