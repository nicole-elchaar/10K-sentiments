{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51300186-a82a-4637-83d5-26c6467c1fa6",
   "metadata": {},
   "source": [
    "# Build Sample\n",
    "\n",
    "After running *download_text_files.ipynb*, we can now build the sample of data to use in the analysis.  The main output of this file is *output/analysis_sample.csv* which includes the following:\n",
    "1. 5 positive sentiment scores\n",
    "1. 5 negative sentiment scores\n",
    "1. a return variable from the day of the 10-K's release to two days following\n",
    "1. a return variable from two days after the 10-K's release to ten days following \n",
    "1. the 10-K's word count\n",
    "1. the 10-K's unique word count\n",
    "1. accounting variables from the CCM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f53bea-fefb-478f-9ba0-640fe7437e3e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a70a4a-16f5-4b0c-b81d-8959032ae55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File and text handling\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from near_regex import NEAR_regex\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Gathering 2022 returns\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "# Get filing dates from SEC EDGAR\n",
    "from requests_html import HTMLSession\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfadaba-7f99-4f53-8278-18682dc448ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and file handling\n",
    "input_dir = 'inputs'\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Inputs\n",
    "topic_path = input_dir + '/topic_list.csv'\n",
    "sp500_path = input_dir + '/s&p500_2022.csv'\n",
    "firm_10k_path = '10k_files/sec-edgar-filings'\n",
    "firm_10k_clean_path = '10k_files/clean'\n",
    "\n",
    "# Outputs\n",
    "sentiment_save_path = output_dir + '/ticker_sentiments.csv'    # store intermediate results\n",
    "returns_save_path = output_dir + '/ticker_returns.csv'         # store intermediate results\n",
    "final_save_path = output_dir + '/analysis_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77672b37-cd40-4d2a-afd8-e1bd2b8ec9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>CIK</th>\n",
       "      <th>truth_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>66740</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>91142</td>\n",
       "      <td>AOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>1800</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>1551152</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>1467373</td>\n",
       "      <td>ACN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>1041061</td>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>877212</td>\n",
       "      <td>ZBRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>1136869</td>\n",
       "      <td>ZBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorporation</td>\n",
       "      <td>109380</td>\n",
       "      <td>0000109380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>1555280</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol              Security      CIK  truth_path\n",
       "0      MMM                    3M    66740         MMM\n",
       "1      AOS           A. O. Smith    91142         AOS\n",
       "2      ABT                Abbott     1800         ABT\n",
       "3     ABBV                AbbVie  1551152        ABBV\n",
       "4      ACN             Accenture  1467373         ACN\n",
       "..     ...                   ...      ...         ...\n",
       "498    YUM           Yum! Brands  1041061         YUM\n",
       "499   ZBRA    Zebra Technologies   877212        ZBRA\n",
       "500    ZBH         Zimmer Biomet  1136869         ZBH\n",
       "501   ZION  Zions Bancorporation   109380  0000109380\n",
       "502    ZTS                Zoetis  1555280         ZTS\n",
       "\n",
       "[503 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load S&P500 companies into a dataframe\n",
    "try:\n",
    "    sp500_orig = pd.read_csv(sp500_path)[['Symbol', 'Security', 'CIK', 'truth_path']]\n",
    "except Exception as error:\n",
    "    print('Please run the contents of download_text_files.ipynb before proceeding')\n",
    "    print(repr(error))\n",
    "    \n",
    "sp500_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b45f5f-e4de-4d83-8ae1-014115d1b1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load 2022 returns\n",
    "\n",
    "Because this step is not costly compared to others, we gather the filing dates regardless of whether we have done so before.\n",
    "\n",
    "Once we have the filing dates, we extract only the 11 days following the announcement.  We then can compute returns for each period of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb63301-4fa8-4f8d-94a5-a06e6671f73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████▎                                                | 197/503 [00:52<01:18,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error finding accession number for ticker FRC, cik 1132979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▉                                              | 213/503 [00:55<01:19,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error finding accession number for ticker GEHC, cik 1932393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████▎             | 417/503 [01:45<00:30,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error finding accession number for ticker SBNY, cik 1288784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 503/503 [02:05<00:00,  4.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>CIK</th>\n",
       "      <th>truth_path</th>\n",
       "      <th>filing_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>66740</td>\n",
       "      <td>MMM</td>\n",
       "      <td>2022-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>91142</td>\n",
       "      <td>AOS</td>\n",
       "      <td>2022-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>1800</td>\n",
       "      <td>ABT</td>\n",
       "      <td>2022-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>1551152</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>2022-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>1467373</td>\n",
       "      <td>ACN</td>\n",
       "      <td>2022-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>1041061</td>\n",
       "      <td>YUM</td>\n",
       "      <td>2022-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>877212</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>2022-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>1136869</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>2022-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorporation</td>\n",
       "      <td>109380</td>\n",
       "      <td>0000109380</td>\n",
       "      <td>2022-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>1555280</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022-02-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol              Security      CIK  truth_path filing_date\n",
       "0      MMM                    3M    66740         MMM  2022-02-09\n",
       "1      AOS           A. O. Smith    91142         AOS  2022-02-11\n",
       "2      ABT                Abbott     1800         ABT  2022-02-18\n",
       "3     ABBV                AbbVie  1551152        ABBV  2022-02-18\n",
       "4      ACN             Accenture  1467373         ACN  2022-10-12\n",
       "..     ...                   ...      ...         ...         ...\n",
       "498    YUM           Yum! Brands  1041061         YUM  2022-02-28\n",
       "499   ZBRA    Zebra Technologies   877212        ZBRA  2022-02-10\n",
       "500    ZBH         Zimmer Biomet  1136869         ZBH  2022-02-25\n",
       "501   ZION  Zions Bancorporation   109380  0000109380  2022-02-25\n",
       "502    ZTS                Zoetis  1555280         ZTS  2022-02-15\n",
       "\n",
       "[503 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the 2022 returns in a separate table\n",
    "sp500_rets = sp500_orig.copy()\n",
    "\n",
    "# Get the filing date for each 10-K\n",
    "session = HTMLSession()\n",
    "\n",
    "for i in tqdm(range(len(sp500_rets))):\n",
    "    tic = sp500_rets['Symbol'].iloc[i]\n",
    "    cik = sp500_rets['CIK'].iloc[i]\n",
    "    truth_path = sp500_rets['truth_path'].iloc[i]\n",
    "    \n",
    "    if not os.path.exists(fr'{firm_10k_path}/{truth_path}/10-K/'):\n",
    "        print(f'Error finding accession number for ticker {tic}, cik {cik}')\n",
    "        continue\n",
    "    accession = os.listdir(fr'{firm_10k_path}/{truth_path}/10-K/')[0]\n",
    "    \n",
    "    url = f'https://www.sec.gov/Archives/edgar/data/{cik}/{accession}-index.html'\n",
    "    r = session.get(url)\n",
    "    try:\n",
    "        sp500_rets.loc[i, 'filing_date'] = r.html.find('.info', first=True).text\n",
    "    except Exception as error:\n",
    "        print(f'Could not get filing date for ticker {tic}, cik {cik}, accession number {accession}: {repr(error)}')\n",
    "    sleep(0.1)\n",
    "\n",
    "sp500_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db8388d-726a-4d46-aeb5-01c7e2700566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>-0.011276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>0.030954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>0.014362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JJSF</td>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>0.012459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587061</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>-0.017551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587062</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>-0.114089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587063</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>0.033089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587064</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>0.080827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587065</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.011164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2587066 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker       date       ret\n",
       "0         JJSF 2021-12-01 -0.011276\n",
       "1         JJSF 2021-12-02  0.030954\n",
       "2         JJSF 2021-12-03  0.000287\n",
       "3         JJSF 2021-12-06  0.014362\n",
       "4         JJSF 2021-12-07  0.012459\n",
       "...        ...        ...       ...\n",
       "2587061   TSLA 2022-12-23 -0.017551\n",
       "2587062   TSLA 2022-12-27 -0.114089\n",
       "2587063   TSLA 2022-12-28  0.033089\n",
       "2587064   TSLA 2022-12-29  0.080827\n",
       "2587065   TSLA 2022-12-30  0.011164\n",
       "\n",
       "[2587066 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download 2022 CSRP returns\n",
    "url = \"https://github.com/LeDataSciFi/data/raw/main/Stock%20Returns%20(CRSP)/crsp_2022_only.zip\"\n",
    "with urlopen(url) as request:\n",
    "    data = BytesIO(request.read())\n",
    "\n",
    "with ZipFile(data) as archive:\n",
    "    with archive.open(archive.namelist()[0]) as stata:\n",
    "        stock_rets = pd.read_stata(stata)\n",
    "\n",
    "stock_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9717040-92bd-47cf-abbe-fd5dc8f6d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>CIK</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>ret_t-t2</th>\n",
       "      <th>ret_t3-t10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>796343</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>-0.015915</td>\n",
       "      <td>0.004955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LMT</td>\n",
       "      <td>Lockheed Martin</td>\n",
       "      <td>936468</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>-0.034930</td>\n",
       "      <td>0.057001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLB</td>\n",
       "      <td>Schlumberger</td>\n",
       "      <td>87347</td>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>0.066684</td>\n",
       "      <td>0.970083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URI</td>\n",
       "      <td>United Rentals</td>\n",
       "      <td>1067701</td>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>0.072747</td>\n",
       "      <td>0.202582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTC</td>\n",
       "      <td>Intel</td>\n",
       "      <td>50863</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>0.660988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>KEYS</td>\n",
       "      <td>Keysight</td>\n",
       "      <td>1601046</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>-0.993890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>Broadcom Inc.</td>\n",
       "      <td>1730168</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>0.827125</td>\n",
       "      <td>-0.993797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>6951</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>0.818515</td>\n",
       "      <td>-0.993813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>NDSN</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>72331</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>0.888110</td>\n",
       "      <td>-0.993850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies</td>\n",
       "      <td>1090872</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>0.877291</td>\n",
       "      <td>-0.993940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol              Security      CIK filing_date  ret_t-t2  ret_t3-t10\n",
       "0     ADBE            Adobe Inc.   796343  2022-01-21 -0.015915    0.004955\n",
       "1      LMT       Lockheed Martin   936468  2022-01-25 -0.034930    0.057001\n",
       "2      SLB          Schlumberger    87347  2022-01-26  0.066684    0.970083\n",
       "3      URI        United Rentals  1067701  2022-01-26  0.072747    0.202582\n",
       "4     INTC                 Intel    50863  2022-01-27  0.165922    0.660988\n",
       "..     ...                   ...      ...         ...       ...         ...\n",
       "492   KEYS              Keysight  1601046  2022-12-15  0.864134   -0.993890\n",
       "493   AVGO         Broadcom Inc.  1730168  2022-12-16  0.827125   -0.993797\n",
       "494   AMAT     Applied Materials     6951  2022-12-16  0.818515   -0.993813\n",
       "495   NDSN   Nordson Corporation    72331  2022-12-19  0.888110   -0.993850\n",
       "496      A  Agilent Technologies  1090872  2022-12-21  0.877291   -0.993940\n",
       "\n",
       "[497 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on filing date, add return from t to t+2 and from t+3 to t+10\n",
    "combined_rets = sp500_rets.merge(\n",
    "        stock_rets.rename(columns={'ticker':'Symbol'}),\n",
    "        on='Symbol',\n",
    "        how='left',\n",
    "        validate='1:m')\n",
    "combined_rets = combined_rets.query('filing_date <= date') \\\n",
    "        .sort_values(by='date') \\\n",
    "        .groupby('Symbol') \\\n",
    "        .head(11)\n",
    "combined_rets['agg_ret'] = 1 + combined_rets['ret']\n",
    "\n",
    "combined_rets['ret_t-t2'] = combined_rets.groupby('Symbol') \\\n",
    "        .head(3)['agg_ret'] \\\n",
    "        .cumprod() - 1\n",
    "combined_rets['ret_t3-t10'] = combined_rets.groupby('Symbol') \\\n",
    "        .tail(8)['agg_ret'] \\\n",
    "        .cumprod() - 1\n",
    "final_rets = combined_rets.groupby('Symbol') \\\n",
    "        .head(3).groupby('Symbol') \\\n",
    "        .tail(1)[['Symbol', 'Security', 'CIK', 'filing_date', 'ret_t-t2']]\n",
    "final_rets = final_rets.merge(\n",
    "        combined_rets.groupby('Symbol') \\\n",
    "                .tail(1)[['Symbol', 'Security', 'CIK', 'ret_t3-t10']],\n",
    "        on=['Symbol', 'Security', 'CIK'],\n",
    "        validate='1:1',\n",
    "        how='left')\n",
    "\n",
    "final_rets.to_csv(returns_save_path, index=False)\n",
    "final_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba1f68-1387-4217-9abc-e582e61f1a56",
   "metadata": {},
   "source": [
    "## Clean 10-Ks\n",
    "\n",
    "For each 10-K, we remove xml and html tags, extracting only the text.  We make the entire document lowercase and keep only words. If this step has already been done, we skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a37c5b-5e39-4162-98c0-6f06aef4a0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████▏                           | 326/503 [00:00<00:00, 647.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find 10-K for ticker FRC\n",
      "Cannot find 10-K for ticker GEHC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 503/503 [00:00<00:00, 615.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find 10-K for ticker SBNY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(firm_10k_clean_path, exist_ok=True)\n",
    "sp500_sents = sp500_orig.copy()\n",
    "\n",
    "for i in tqdm(range(len(sp500_sents))):\n",
    "    tic = sp500_sents['Symbol'].iloc[i]\n",
    "    truth_path = sp500_sents['truth_path'].iloc[i]    # Locate the 10-K\n",
    "\n",
    "    # Check existence of path\n",
    "    if not os.path.exists(fr'{firm_10k_path}/{truth_path}'):\n",
    "        print(f'Cannot find 10-K for ticker {tic}')\n",
    "        continue\n",
    "    \n",
    "    # Create clean path\n",
    "    os.makedirs(fr'{firm_10k_clean_path}/{truth_path}', exist_ok=True)\n",
    "    \n",
    "    for path in glob.glob(fr'{firm_10k_path}/{truth_path}/*/*/*.html'):\n",
    "        # Check existence of cleaned 10-K\n",
    "        if os.path.exists(fr'{firm_10k_clean_path}/{truth_path}/10-K.txt'):\n",
    "            continue\n",
    "        \n",
    "        # Open and clean the 10-K\n",
    "        with open(path, 'rb') as report_file:\n",
    "            html = report_file.read()\n",
    "        soup = BeautifulSoup(html, 'lxml-xml')\n",
    "        for div in soup.find_all(\"div\", {'style': 'display:none'}):\n",
    "            div.dintlpose()                       # remove hidden divs,\n",
    "        lower = soup.get_text().lower()           # uppercase,\n",
    "        no_punc = re.sub(r'\\W', ' ', lower)       # non-alpha-numeric,\n",
    "        cleaned = re.sub(r'\\s+', ' ', no_punc)    # single-space\n",
    "        \n",
    "        # Persist changes to the clean directory\n",
    "        result_path = fr'{firm_10k_clean_path}/{truth_path}/10-K.txt' \n",
    "        with open(result_path, 'wb') as result_file:\n",
    "            result_file.write(cleaned.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d419bcd-216c-4760-a4fe-180b89c7c21f",
   "metadata": {},
   "source": [
    "## Load sentiment dictionaries\n",
    "\n",
    "Now, we load the sentiment dictionaries.\n",
    "\n",
    "For the LM dictionary, we only keep positive values.  The dictionary was released in 2021, and the year that any word was added to the list is included as a positive value.  The year a word was removed from the list, it is included as a negative value.  Any negative values have been removed from the list during some release, so we should only keep the positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8025a5e8-5384-4cc7-87ac-0ebdad9212af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Dictionaries\n",
    "with open('inputs/ML_negative_unigram.txt', 'r') as file:\n",
    "    BHR_negative = [line.strip() for line in file]\n",
    "with open('inputs/ML_positive_unigram.txt', 'r') as file:\n",
    "    BHR_positive = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8936ac5-2136-4730-8a72-c582d7d5c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM Dictionaries\n",
    "LM = pd.read_csv('inputs/LM_MasterDictionary_1993-2021.csv')\n",
    "LM_negative = LM.query('Negative > 0')['Word'].to_list()\n",
    "LM_positive = LM.query('Positive > 0')['Word'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc85e2a-0ec6-4231-bafd-a00dc9c71ec1",
   "metadata": {},
   "source": [
    "## Generate sentiment regex\n",
    "\n",
    "We start by gathering the sentiments into regex patterns.  We define a function to generate the NEAR_regex for each pair of two topics, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab6e2a7-47f6-446d-8dbf-558eeb76bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather sentiments into regex\n",
    "BHR_negative_regex = '(' + '|'.join(BHR_negative).lower() + ')'\n",
    "BHR_positive_regex = '(' + '|'.join(BHR_positive).lower() + ')'\n",
    "LM_negative_regex = '(' + '|'.join(LM_negative).lower() + ')'\n",
    "LM_positive_regex = '(' + '|'.join(LM_positive).lower() + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201d2cd9-291f-4bd2-bfb8-c3fe6e393b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic regex\n",
    "def NEAR_regex_helper(topic_df, topic_name, max_words_between=5):\n",
    "    topic_list = topic_df['term'].loc[topic_df['type'] == topic_name + '_topic']\n",
    "    positive_list = topic_df['term'].loc[topic_df['type'] == topic_name + '_positive']\n",
    "    negative_list = topic_df['term'].loc[topic_df['type'] == topic_name + '_negative']\n",
    "    \n",
    "    topic_regex = '(' + '|'.join(topic_list).lower() + ')'\n",
    "    positive_regex = '(' + '|'.join(positive_list).lower() + ')'\n",
    "    negative_regex = '(' + '|'.join(negative_list).lower() + ')'\n",
    "    \n",
    "    positive_regex = NEAR_regex([topic_regex, positive_regex], max_words_between=max_words_between)\n",
    "    negative_regex = NEAR_regex([topic_regex, negative_regex], max_words_between=max_words_between)\n",
    "    return [positive_regex, negative_regex]\n",
    "\n",
    "# Read in file\n",
    "if not os.path.exists(topic_path):\n",
    "    print(f'Cannot find path {topic_path} to topic list')\n",
    "else:\n",
    "    topic_df = pd.read_csv(topic_path)\n",
    "    \n",
    "    # Get topics from list\n",
    "    fs_positive_regex, fs_negative_regex = NEAR_regex_helper(topic_df, 'fs')\n",
    "    cg_positive_regex, cg_negative_regex = NEAR_regex_helper(topic_df, 'cg')\n",
    "    ecom_positive_regex, ecom_negative_regex = NEAR_regex_helper(topic_df, 'ecom')\n",
    "    \n",
    "    ''' Other existing topics\n",
    "    esg_positive_regex, esg_negative_regex = NEAR_regex_helper(topic_df, 'esg')\n",
    "    intl_positive_regex, intl_negative_regex = NEAR_regex_helper(topic_df, 'intl')\n",
    "    bio_positive_regex, bio_negative_regex = NEAR_regex_helper(topic_df, 'bio')\n",
    "    cs_positive_regex, cs_negative_regex = NEAR_regex_helper(topic_df, 'cs')\n",
    "    csat_positive_regex, csat_negative_regex = NEAR_regex_helper(topic_df, 'csat')\n",
    "    esat_positive_regex, esat_negative_regex = NEAR_regex_helper(topic_df, 'esat')\n",
    "    fp_positive_regex, fp_negative_regex = NEAR_regex_helper(topic_df, 'fp')\n",
    "    fs_positive_regex, fs_negative_regex = NEAR_regex_helper(topic_df, 'fs')\n",
    "    ia_positive_regex, ia_negative_regex = NEAR_regex_helper(topic_df, 'ia')\n",
    "    re_positive_regex, re_negative_regex = NEAR_regex_helper(topic_df, 're')\n",
    "    sc_positive_regex, sc_negative_regex = NEAR_regex_helper(topic_df, 'sc')\n",
    "    tech_positive_regex, tech_negative_regex = NEAR_regex_helper(topic_df, 'tech')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ef2d5-3bbd-449a-be39-33743bf409f1",
   "metadata": {},
   "source": [
    "## Load each firm and add sentiment variables\n",
    "\n",
    "Now, we add the sentiment measures for each 10-K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b9eb13-c23d-4798-98d2-0fb2720d8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify adding a value to a given row\n",
    "def add_sentiment(df, i, sentiment_name, search, text, word_count):\n",
    "    df.loc[i, sentiment_name] = len(re.findall(search, text)) / word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81201d43-c23b-4601-bade-b3eadad933cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>bhr_negative</th>\n",
       "      <th>bhr_positive</th>\n",
       "      <th>lm_negative</th>\n",
       "      <th>lm_positive</th>\n",
       "      <th>esg_negative</th>\n",
       "      <th>esg_positive</th>\n",
       "      <th>intl_negative</th>\n",
       "      <th>intl_positive</th>\n",
       "      <th>...</th>\n",
       "      <th>fp_negative</th>\n",
       "      <th>fp_positive</th>\n",
       "      <th>ia_negative</th>\n",
       "      <th>ia_positive</th>\n",
       "      <th>re_negative</th>\n",
       "      <th>re_positive</th>\n",
       "      <th>sc_negative</th>\n",
       "      <th>sc_positive</th>\n",
       "      <th>tech_negative</th>\n",
       "      <th>tech_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5425.424000</td>\n",
       "      <td>69504.586000</td>\n",
       "      <td>0.038030</td>\n",
       "      <td>0.039918</td>\n",
       "      <td>0.036081</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1177.831997</td>\n",
       "      <td>28943.930805</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>1575.000000</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4767.250000</td>\n",
       "      <td>51384.750000</td>\n",
       "      <td>0.035457</td>\n",
       "      <td>0.036979</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5324.500000</td>\n",
       "      <td>64916.500000</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.039824</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>0.014822</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5893.500000</td>\n",
       "      <td>80526.000000</td>\n",
       "      <td>0.040611</td>\n",
       "      <td>0.043145</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>0.016067</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10469.000000</td>\n",
       "      <td>271760.000000</td>\n",
       "      <td>0.051376</td>\n",
       "      <td>0.056662</td>\n",
       "      <td>0.055229</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_word_count     word_count  bhr_negative  bhr_positive  \\\n",
       "count         500.000000     500.000000    500.000000    500.000000   \n",
       "mean         5425.424000   69504.586000      0.038030      0.039918   \n",
       "std          1177.831997   28943.930805      0.004226      0.005064   \n",
       "min           460.000000    1575.000000      0.015659      0.010931   \n",
       "25%          4767.250000   51384.750000      0.035457      0.036979   \n",
       "50%          5324.500000   64916.500000      0.038217      0.039824   \n",
       "75%          5893.500000   80526.000000      0.040611      0.043145   \n",
       "max         10469.000000  271760.000000      0.051376      0.056662   \n",
       "\n",
       "       lm_negative  lm_positive  esg_negative  esg_positive  intl_negative  \\\n",
       "count   500.000000   500.000000    500.000000    500.000000     500.000000   \n",
       "mean      0.036081     0.014795      0.000827      0.001332       0.000133   \n",
       "std       0.004679     0.002147      0.000664      0.000576       0.000112   \n",
       "min       0.023693     0.004394      0.000000      0.000295       0.000000   \n",
       "25%       0.033086     0.013601      0.000435      0.001026       0.000055   \n",
       "50%       0.035853     0.014822      0.000568      0.001195       0.000107   \n",
       "75%       0.038983     0.016067      0.000910      0.001456       0.000180   \n",
       "max       0.055229     0.021395      0.004063      0.004683       0.000837   \n",
       "\n",
       "       intl_positive  ...  fp_negative  fp_positive  ia_negative  ia_positive  \\\n",
       "count     500.000000  ...   500.000000   500.000000   500.000000   500.000000   \n",
       "mean        0.000338  ...     0.000562     0.000671     0.000018     0.000051   \n",
       "std         0.000216  ...     0.000229     0.000283     0.000025     0.000055   \n",
       "min         0.000000  ...     0.000000     0.000000     0.000000     0.000000   \n",
       "25%         0.000177  ...     0.000400     0.000483     0.000000     0.000013   \n",
       "50%         0.000308  ...     0.000522     0.000624     0.000013     0.000036   \n",
       "75%         0.000448  ...     0.000681     0.000833     0.000024     0.000071   \n",
       "max         0.001453  ...     0.001421     0.001851     0.000172     0.000408   \n",
       "\n",
       "       re_negative  re_positive  sc_negative  sc_positive  tech_negative  \\\n",
       "count   500.000000   500.000000   500.000000   500.000000     500.000000   \n",
       "mean      0.000009     0.000008     0.002397     0.000015       0.000012   \n",
       "std       0.000014     0.000014     0.000889     0.000022       0.000045   \n",
       "min       0.000000     0.000000     0.000161     0.000000       0.000000   \n",
       "25%       0.000000     0.000000     0.001794     0.000000       0.000000   \n",
       "50%       0.000000     0.000000     0.002320     0.000010       0.000000   \n",
       "75%       0.000015     0.000013     0.002906     0.000021       0.000016   \n",
       "max       0.000109     0.000094     0.006602     0.000169       0.000953   \n",
       "\n",
       "       tech_positive  \n",
       "count     500.000000  \n",
       "mean        0.000047  \n",
       "std         0.000054  \n",
       "min         0.000000  \n",
       "25%         0.000014  \n",
       "50%         0.000035  \n",
       "75%         0.000064  \n",
       "max         0.000667  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and get the sentiment of clean 10-Ks\n",
    "temp_path = output_dir + '/ticker_sentiments_temp.csv'\n",
    "\n",
    "# Compute sentiment ariables\n",
    "if not os.path.exists(sentiment_save_path):\n",
    "    for i in tqdm(range(len(sp500_sents))):\n",
    "        tic = sp500_sents['Symbol'].iloc[i]\n",
    "        truth_path = sp500_sents['truth_path'].iloc[i]    # Get the path where the clean 10-K is stored\n",
    "\n",
    "        # Check existence of path\n",
    "        if not os.path.exists(fr'{firm_10k_clean_path}/{truth_path}'):\n",
    "            print(f'Cannot find clean 10-K for ticker {tic}')\n",
    "            continue\n",
    "\n",
    "        for path in glob.glob(fr'{firm_10k_clean_path}/{truth_path}/*.txt'):\n",
    "            with open(path, 'rb') as report_file:\n",
    "                cleaned = str(report_file.read())\n",
    "\n",
    "            # Add word count and unique word count\n",
    "            word_list = re.findall(r'\\w+', cleaned)\n",
    "            sp500_sents.loc[i, 'unique_word_count'] = len(set(word_list))\n",
    "            word_count = len(word_list)\n",
    "            sp500_sents.loc[i, 'word_count'] = word_count\n",
    "\n",
    "            # Gather valence variables\n",
    "            add_sentiment(sp500_sents, i, 'bhr_negative', BHR_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'bhr_positive', BHR_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'lm_negative', LM_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'lm_positive', LM_positive_regex, cleaned, word_count)\n",
    "\n",
    "            # Gather topic valence variables\n",
    "            add_sentiment(sp500_sents, i, 'fs_negative', fs_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'fs_positive', fs_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'cg_negative', cg_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'cg_positive', cg_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'ecom_negative', ecom_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'ecom_positive', ecom_positive_regex, cleaned, word_count)\n",
    "            \n",
    "            ''' Other existing topics\n",
    "            add_sentiment(sp500_sents, i, 'esg_negative', esg_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'esg_positive', esg_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'intl_negative', intl_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'intl_positive', intl_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'bio_negative', bio_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'bio_positive', bio_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'cs_negative', cs_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'cs_positive', cs_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'csat_negative', csat_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'csat_positive', csat_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'esat_negative', esat_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'esat_positive', esat_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'fp_negative', fp_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'fp_positive', fp_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'fs_negative', fs_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'fs_positive', fs_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'ia_negative', ia_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'ia_positive', ia_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 're_negative', re_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 're_positive', re_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'sc_negative', sc_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'sc_positive', sc_positive_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'tech_negative', tech_negative_regex, cleaned, word_count)\n",
    "            add_sentiment(sp500_sents, i, 'tech_positive', tech_positive_regex, cleaned, word_count)\n",
    "            '''\n",
    "\n",
    "            # Save intermittently\n",
    "            if i % 50 == 0:\n",
    "                sp500_sents.to_csv(temp_path, index=False)\n",
    "\n",
    "    sp500_sents.to_csv(sentiment_save_path, index=False)\n",
    "else:\n",
    "    # Load existing sentiments\n",
    "    sp500_sents = pd.read_csv(sentiment_save_path)\n",
    "sp500_sents.drop(['CIK'], axis=1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685d86b-4e36-4871-aa3a-0f0a11942775",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Download 2021 CCM Data\n",
    "\n",
    "We download CCM data from GitHub to incorporate additional firm information into our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d29691e2-acc7-4588-bb85-0bd161b71d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CRSP dataframe\n",
    "crsp_2021_url = 'https://github.com/LeDataSciFi/data/raw/main/Firm%20Year%20Datasets%20(Compustat)/2021_ccm_cleaned.dta'\n",
    "crsp_2021 = pd.read_stata(crsp_2021_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a77790-f2e0-4ca6-ab73-2ab72874e25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>CIK</th>\n",
       "      <th>truth_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>66740</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>91142</td>\n",
       "      <td>AOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>1800</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>1551152</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>1467373</td>\n",
       "      <td>ACN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol     Security      CIK truth_path\n",
       "0    MMM           3M    66740        MMM\n",
       "1    AOS  A. O. Smith    91142        AOS\n",
       "2    ABT       Abbott     1800        ABT\n",
       "3   ABBV       AbbVie  1551152       ABBV\n",
       "4    ACN    Accenture  1467373        ACN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f652876-eee6-4dae-b968-015bb82a85b9",
   "metadata": {},
   "source": [
    "## Merge Sentiment Scores, Returns, and 2021 CCM Data\n",
    "\n",
    "Now, we merge our sets together and save the final dataframe for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d81be0c-7d07-41a4-a745-421794470c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>CIK</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>ret_t-t2</th>\n",
       "      <th>ret_t3-t10</th>\n",
       "      <th>truth_path</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>bhr_negative</th>\n",
       "      <th>...</th>\n",
       "      <th>mb</th>\n",
       "      <th>prof_a</th>\n",
       "      <th>ppe_a</th>\n",
       "      <th>cash_a</th>\n",
       "      <th>xrd_a</th>\n",
       "      <th>dltt_a</th>\n",
       "      <th>invopps_FG09</th>\n",
       "      <th>sales_g</th>\n",
       "      <th>dv_a</th>\n",
       "      <th>short_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>796343</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>-0.015915</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>5488.0</td>\n",
       "      <td>56254.0</td>\n",
       "      <td>0.038131</td>\n",
       "      <td>...</td>\n",
       "      <td>12.136953</td>\n",
       "      <td>0.233582</td>\n",
       "      <td>0.077677</td>\n",
       "      <td>0.212841</td>\n",
       "      <td>0.093242</td>\n",
       "      <td>0.167982</td>\n",
       "      <td>11.908058</td>\n",
       "      <td>0.226686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LMT</td>\n",
       "      <td>Lockheed Martin</td>\n",
       "      <td>936468</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>-0.034930</td>\n",
       "      <td>0.057001</td>\n",
       "      <td>LMT</td>\n",
       "      <td>5251.0</td>\n",
       "      <td>75996.0</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>...</td>\n",
       "      <td>2.677847</td>\n",
       "      <td>0.205630</td>\n",
       "      <td>0.174886</td>\n",
       "      <td>0.070843</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.251017</td>\n",
       "      <td>2.188377</td>\n",
       "      <td>0.025169</td>\n",
       "      <td>0.057791</td>\n",
       "      <td>0.025340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLB</td>\n",
       "      <td>Schlumberger</td>\n",
       "      <td>87347</td>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>0.066684</td>\n",
       "      <td>0.970083</td>\n",
       "      <td>SLB</td>\n",
       "      <td>3735.0</td>\n",
       "      <td>35258.0</td>\n",
       "      <td>0.038289</td>\n",
       "      <td>...</td>\n",
       "      <td>1.651087</td>\n",
       "      <td>0.117680</td>\n",
       "      <td>0.214931</td>\n",
       "      <td>0.075619</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>0.335188</td>\n",
       "      <td>1.369396</td>\n",
       "      <td>-0.028473</td>\n",
       "      <td>0.016839</td>\n",
       "      <td>0.072956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URI</td>\n",
       "      <td>United Rentals</td>\n",
       "      <td>1067701</td>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>0.072747</td>\n",
       "      <td>0.202582</td>\n",
       "      <td>URI</td>\n",
       "      <td>4654.0</td>\n",
       "      <td>60311.0</td>\n",
       "      <td>0.040142</td>\n",
       "      <td>...</td>\n",
       "      <td>1.890685</td>\n",
       "      <td>0.212399</td>\n",
       "      <td>0.589198</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463237</td>\n",
       "      <td>1.597794</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTC</td>\n",
       "      <td>Intel</td>\n",
       "      <td>50863</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>0.660988</td>\n",
       "      <td>INTC</td>\n",
       "      <td>6519.0</td>\n",
       "      <td>68626.0</td>\n",
       "      <td>0.038775</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678206</td>\n",
       "      <td>0.201145</td>\n",
       "      <td>0.378811</td>\n",
       "      <td>0.168717</td>\n",
       "      <td>0.090199</td>\n",
       "      <td>0.200735</td>\n",
       "      <td>1.454506</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>0.123678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>BF.B</td>\n",
       "      <td>Brown–Forman</td>\n",
       "      <td>14693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0000014693</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>44204.0</td>\n",
       "      <td>0.036897</td>\n",
       "      <td>...</td>\n",
       "      <td>5.639590</td>\n",
       "      <td>0.210576</td>\n",
       "      <td>0.148909</td>\n",
       "      <td>0.137141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325279</td>\n",
       "      <td>5.401004</td>\n",
       "      <td>0.136377</td>\n",
       "      <td>0.130394</td>\n",
       "      <td>0.115614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>FRC</td>\n",
       "      <td>First Republic Bank</td>\n",
       "      <td>1132979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001132979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>GEHC</td>\n",
       "      <td>GE HealthCare</td>\n",
       "      <td>1932393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001932393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>SBNY</td>\n",
       "      <td>Signature Bank</td>\n",
       "      <td>1288784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0001288784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>WELL</td>\n",
       "      <td>Welltower</td>\n",
       "      <td>766704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0000766704</td>\n",
       "      <td>10469.0</td>\n",
       "      <td>110010.0</td>\n",
       "      <td>0.027870</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol             Security      CIK filing_date  ret_t-t2  ret_t3-t10  \\\n",
       "0     ADBE           Adobe Inc.   796343  2022-01-21 -0.015915    0.004955   \n",
       "1      LMT      Lockheed Martin   936468  2022-01-25 -0.034930    0.057001   \n",
       "2      SLB         Schlumberger    87347  2022-01-26  0.066684    0.970083   \n",
       "3      URI       United Rentals  1067701  2022-01-26  0.072747    0.202582   \n",
       "4     INTC                Intel    50863  2022-01-27  0.165922    0.660988   \n",
       "..     ...                  ...      ...         ...       ...         ...   \n",
       "498   BF.B         Brown–Forman    14693         NaN       NaN         NaN   \n",
       "499    FRC  First Republic Bank  1132979         NaN       NaN         NaN   \n",
       "500   GEHC        GE HealthCare  1932393         NaN       NaN         NaN   \n",
       "501   SBNY       Signature Bank  1288784         NaN       NaN         NaN   \n",
       "502   WELL            Welltower   766704         NaN       NaN         NaN   \n",
       "\n",
       "     truth_path  unique_word_count  word_count  bhr_negative  ...         mb  \\\n",
       "0          ADBE             5488.0     56254.0      0.038131  ...  12.136953   \n",
       "1           LMT             5251.0     75996.0      0.041739  ...   2.677847   \n",
       "2           SLB             3735.0     35258.0      0.038289  ...   1.651087   \n",
       "3           URI             4654.0     60311.0      0.040142  ...   1.890685   \n",
       "4          INTC             6519.0     68626.0      0.038775  ...   1.678206   \n",
       "..          ...                ...         ...           ...  ...        ...   \n",
       "498  0000014693             4815.0     44204.0      0.036897  ...   5.639590   \n",
       "499  0001132979                NaN         NaN           NaN  ...        NaN   \n",
       "500  0001932393                NaN         NaN           NaN  ...        NaN   \n",
       "501  0001288784                NaN         NaN           NaN  ...        NaN   \n",
       "502  0000766704            10469.0    110010.0      0.027870  ...        NaN   \n",
       "\n",
       "       prof_a     ppe_a    cash_a     xrd_a    dltt_a  invopps_FG09   sales_g  \\\n",
       "0    0.233582  0.077677  0.212841  0.093242  0.167982     11.908058  0.226686   \n",
       "1    0.205630  0.174886  0.070843  0.029485  0.251017      2.188377  0.025169   \n",
       "2    0.117680  0.214931  0.075619  0.013346  0.335188      1.369396 -0.028473   \n",
       "3    0.212399  0.589198  0.007096  0.000000  0.463237      1.597794  0.139039   \n",
       "4    0.201145  0.378811  0.168717  0.090199  0.200735      1.454506  0.014859   \n",
       "..        ...       ...       ...       ...       ...           ...       ...   \n",
       "498  0.210576  0.148909  0.137141  0.000000  0.325279      5.401004  0.136377   \n",
       "499       NaN       NaN       NaN       NaN       NaN           NaN       NaN   \n",
       "500       NaN       NaN       NaN       NaN       NaN           NaN       NaN   \n",
       "501       NaN       NaN       NaN       NaN       NaN           NaN       NaN   \n",
       "502       NaN       NaN       NaN       NaN       NaN           NaN       NaN   \n",
       "\n",
       "         dv_a  short_debt  \n",
       "0    0.000000    0.020758  \n",
       "1    0.057791    0.025340  \n",
       "2    0.016839    0.072956  \n",
       "3    0.000000    0.105443  \n",
       "4    0.033514    0.123678  \n",
       "..        ...         ...  \n",
       "498  0.130394    0.115614  \n",
       "499       NaN         NaN  \n",
       "500       NaN         NaN  \n",
       "501       NaN         NaN  \n",
       "502       NaN         NaN  \n",
       "\n",
       "[503 rows x 108 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_final = final_rets.merge(sp500_sents, on=['Symbol', 'Security', 'CIK'], validate='1:1', how='outer')\n",
    "sp500_final = sp500_final.merge(crsp_2021.rename(columns={'tic':'Symbol'}),\n",
    "        on='Symbol',\n",
    "        how='left',\n",
    "        validate='1:1')\n",
    "sp500_final.to_csv(final_save_path, index=False)\n",
    "sp500_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
